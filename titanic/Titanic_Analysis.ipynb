{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "titanic_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Preprocessing: Drop unnecessary columns and handle missing values\n",
    "titanic_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "titanic_df['Age'].fillna(titanic_df['Age'].median(), inplace=True)\n",
    "titanic_df['Embarked'].fillna('S', inplace=True)\n",
    "#features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "# Convert categorical variables to numerical\n",
    "titanic_df['Sex'] = pd.factorize(titanic_df['Sex'])[0]\n",
    "titanic_df['Embarked'] = pd.factorize(titanic_df['Embarked'])[0]\n",
    "\n",
    "#Preprocessing numerical values\n",
    "scaler = StandardScaler()\n",
    "#numeric_cols = ['Age', 'Fare', 'Pclass']\n",
    "#titanic_df[numeric_cols] = scaler.fit_transform(titanic_df[numeric_cols]) \n",
    "\n",
    "# Split data into train and test sets\n",
    "train_df = titanic_df.sample(frac=0.8, random_state=42)\n",
    "test_df = titanic_df.drop(train_df.index)\n",
    "\n",
    "# Define the input shape and output shape\n",
    "input_shape = (train_df.shape[1] - 1,)\n",
    "output_shape = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "inputs = Input(shape=input_shape, dtype=tf.float32)\n",
    "x = Dense(32, activation='relu')(inputs)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "outputs = Dense(output_shape, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Convert labels to categorical data type\n",
    "train_labels = tf.keras.utils.to_categorical(train_df['Survived'], num_classes=output_shape)\n",
    "test_labels = tf.keras.utils.to_categorical(test_df['Survived'], num_classes=output_shape)\n",
    "\n",
    "train_features = train_df.drop(['Survived'], axis=1)\n",
    "test_features = test_df.drop(['Survived'], axis=1)\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    validation_data=(test_features, test_labels),\n",
    "                    epochs=num_epochs, batch_size=70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class_probabilities = model.predict(test_features)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "true_labels = np.argmax(test_labels, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for training vs validation loss\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "modelFileName = 'models/survivors-classifier.h5'\n",
    "model.save(modelFileName)\n",
    "del model  # deletes the existing model variable\n",
    "print('model saved as', modelFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_data = pd.read_csv('test.csv')\n",
    "passenger_ids = test_data['PassengerId']\n",
    "\n",
    "# Preprocess the test data\n",
    "# ...\n",
    "# Preprocessing: Drop unnecessary columns and handle missing values\n",
    "test_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "test_data['Age'].fillna(test_data['Age'].median(), inplace=True)\n",
    "test_data['Embarked'].fillna('S', inplace=True)\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "test_data['Sex'] = pd.factorize(test_data['Sex'])[0]\n",
    "test_data['Embarked'] = pd.factorize(test_data['Embarked'])[0]\n",
    "\n",
    "# Load the trained TensorFlow model\n",
    "model = tf.keras.models.load_model(modelFileName)\n",
    "\n",
    "# Make predictions on the test data\n",
    "class_probabilities = model.predict(test_data)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the predicted labels to a CSV file\n",
    "submission = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
